{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7ed6df1834b04eb694c1d9f48a9d659e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_239c30aa3e6e42dcbb5d36af94f38ef4",
              "IPY_MODEL_60891a9b234b42f1b235b26750b01255",
              "IPY_MODEL_459be8b74cf1411aae0b8cee5b02e283"
            ],
            "layout": "IPY_MODEL_5159870a6b4d47fdbb1d6a604745a721"
          }
        },
        "239c30aa3e6e42dcbb5d36af94f38ef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c701207fa444dc79a217d0ac1a27bda",
            "placeholder": "​",
            "style": "IPY_MODEL_3bc29ed36c6d4e5fb7e2a70d335312f2",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "60891a9b234b42f1b235b26750b01255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d1153e1dd524cbe937b49fca0141ef9",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_970742ee8cca4573a6cf2acde1b25ba3",
            "value": 4
          }
        },
        "459be8b74cf1411aae0b8cee5b02e283": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64bcf55b041a4703ba0b8bcd967b1355",
            "placeholder": "​",
            "style": "IPY_MODEL_f70189e999e24bfd8f0efee6af64c2fc",
            "value": " 4/4 [01:14&lt;00:00, 16.11s/it]"
          }
        },
        "5159870a6b4d47fdbb1d6a604745a721": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c701207fa444dc79a217d0ac1a27bda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bc29ed36c6d4e5fb7e2a70d335312f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d1153e1dd524cbe937b49fca0141ef9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "970742ee8cca4573a6cf2acde1b25ba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64bcf55b041a4703ba0b8bcd967b1355": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f70189e999e24bfd8f0efee6af64c2fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leemabhena/ait-deeplearning-class/blob/main/AIT_RAG_Assessment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG + LLM Assessment"
      ],
      "metadata": {
        "id": "e1xCp6n57BB2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your task is to create a Retrieval-Augmented Generation (RAG) system using a Large Language Model (LLM). The RAG system should be able to retrieve relevant information from a knowledge base and generate coherent and informative responses to user queries."
      ],
      "metadata": {
        "id": "qmI3jBxK68-G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Steps:\n",
        "\n",
        "1. Choose a domain and collect a suitable dataset of documents (at least 5 documents - PDFs or HTML pages) to serve as the knowledge base for your RAG system. Select one of the following topics:\n",
        "   * latest scientific papers from arxiv.org,\n",
        "   * fiction books released,\n",
        "   * legal documents or,\n",
        "   * social media posts.\n",
        "\n",
        "   Make sure that the documents are newer then the training dataset of the applied LLM. (20 points)\n",
        "\n",
        "2. Create three relevant prompts to the dataset, and one irrelevant prompt. (20 points)\n",
        "\n",
        "3. Load an LLM with at least 5B parameters. (10 points)\n",
        "\n",
        "4. Test the LLM with your prompts. The goal should be that without the collected dataset your model is unable to answer the question. If it gives you a good answer, select another question to answer and maybe a different dataset. (10 points)\n",
        "\n",
        "5. Create a LangChain-based RAG system by setting up a vector database from the documents. (20 points)\n",
        "\n",
        "6. Provide your three relevant and one irrelevant prompts to your RAG system. For the relevant prompts, your RAG system should return relevant answers, and for the irrelevant prompt, an empty answer. (20 points)\n"
      ],
      "metadata": {
        "id": "K3STgq_s6_mV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. I will be using statistical papers, published on May 3rd on the arxvi.org website."
      ],
      "metadata": {
        "id": "DNw7UqKVVBAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# urls of the papers\n",
        "urls = [\n",
        "    \"https://arxiv.org/pdf/2405.00827\", # Overcoming model uncertainty – how equivalence tests can benefit from model averaging\n",
        "    \"https://arxiv.org/pdf/2405.00835\", # Individual-level models of disease transmission incorporating piecewise spatial risk functions\n",
        "    \"https://arxiv.org/pdf/2405.00842\", # Quickest Change Detection with Confusing Change\n",
        "    \"https://arxiv.org/pdf/2405.00859\", # WATCH: A Workflow to Assess Treatment Effect Heterogeneity in Drug Development for Clinical Trial Sponsors\n",
        "    \"https://arxiv.org/pdf/2405.00884\", # What’s So Hard about the Monty Hall Problem?\n",
        "]"
      ],
      "metadata": {
        "id": "kktopTMxVZRN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Three relevant prompts and one irelevant one"
      ],
      "metadata": {
        "id": "g65w1g4MWU40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Relevant prompts\n",
        "prompt1 = \"What is the role of model averaging in overcoming model uncertainty in equivalence tests, as discussed in recent arXiv publications?\"\n",
        "prompt2 = \"How do the proposed non-parametric spatial disease transmission models improve upon traditional parametric forms in estimating infection risk?\"\n",
        "prompt3 = \"What new procedures are proposed in quickest change detection to differentiate between 'bad' and 'confusing' changes, and what guarantees do these procedures offer?\"\n",
        "\n",
        "#Irrelevant prompt\n",
        "i_prompt = \"Which team won Laliga this season?\""
      ],
      "metadata": {
        "id": "XhfBiyCdWUf4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Load an LLM with at least 5B parameters."
      ],
      "metadata": {
        "id": "NqiO5u2nXmN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers>=4.32.0 optimum>=1.12.0 > null\n",
        "!pip install auto-gptq --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu118/ > null\n",
        "!pip install langchain > null\n",
        "!pip install chromadb > null\n",
        "!pip install sentence_transformers > null # ==2.2.2\n",
        "!pip install unstructured > null\n",
        "!pip install pdf2image > null\n",
        "!pip install pdfminer.six > null\n",
        "!pip install unstructured-pytesseract > null\n",
        "!pip install unstructured-inference > null\n",
        "!pip install faiss-gpu > null\n",
        "!pip install pikepdf > null\n",
        "!pip install pypdf > null\n",
        "!pip install accelerate > null\n",
        "!pip install pillow_heif > null\n",
        "!pip install -i https://pypi.org/simple/ bitsandbytes > null"
      ],
      "metadata": {
        "id": "9nwufKe08D3e"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "hV_iIDhQTnf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig, pipeline, BitsAndBytesConfig\n",
        "from textwrap import fill\n",
        "from langchain.prompts import PromptTemplate\n",
        "import locale\n",
        "from langchain.document_loaders import UnstructuredURLLoader\n",
        "from langchain.vectorstores.utils import filter_complex_metadata\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "\n",
        "HUGGINGFACE_UAT=\"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\"\n",
        "login(HUGGINGFACE_UAT)"
      ],
      "metadata": {
        "id": "zb6s85dVT2vB",
        "outputId": "46b3db41-12fc-4624-ee73-bb52f6cdaea5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "\n",
        "quantization_config =  BitsAndBytesConfig(load_in_8bit=True, llm_int8_enable_fp32_cpu_offload=True)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
        "                                             device_map=\"auto\",\n",
        "                                             quantization_config=quantization_config,\n",
        "                                             trust_remote_code=True)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "\n",
        "gen_cfg = GenerationConfig.from_pretrained(model_name)\n",
        "gen_cfg.max_new_tokens=512\n",
        "gen_cfg.temperature=0.0000001 # 0.0 # For RAG we would like to have determenistic answers\n",
        "gen_cfg.return_full_text=True\n",
        "gen_cfg.do_sample=True\n",
        "gen_cfg.repetition_penalty=1.11\n",
        "\n",
        "pipe=pipeline(\n",
        "    task=\"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    generation_config=gen_cfg\n",
        ")\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=pipe)"
      ],
      "metadata": {
        "id": "IGekSUl6Xpdx",
        "outputId": "e4e4383b-b577-4812-ef45-42c6901fef8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230,
          "referenced_widgets": [
            "7ed6df1834b04eb694c1d9f48a9d659e",
            "239c30aa3e6e42dcbb5d36af94f38ef4",
            "60891a9b234b42f1b235b26750b01255",
            "459be8b74cf1411aae0b8cee5b02e283",
            "5159870a6b4d47fdbb1d6a604745a721",
            "4c701207fa444dc79a217d0ac1a27bda",
            "3bc29ed36c6d4e5fb7e2a70d335312f2",
            "5d1153e1dd524cbe937b49fca0141ef9",
            "970742ee8cca4573a6cf2acde1b25ba3",
            "64bcf55b041a4703ba0b8bcd967b1355",
            "f70189e999e24bfd8f0efee6af64c2fc"
          ]
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ed6df1834b04eb694c1d9f48a9d659e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Test the LLM with your prompts. The goal should be that without the collected dataset your model is unable to answer the question. If it gives you a good answer, select another question to answer and maybe a different dataset."
      ],
      "metadata": {
        "id": "VWq3Wg37Y8X0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "{text}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"text\"],\n",
        "    template=template,\n",
        ")\n"
      ],
      "metadata": {
        "id": "P4_FjGhbZAqy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test with first prompt\n",
        "result = llm(prompt.format(text=prompt1))\n",
        "print(fill(result.strip(), width=100))"
      ],
      "metadata": {
        "id": "fTatGB09ZKyW",
        "outputId": "f7d50a65-c811-46b0-e2be-f0e3548e394d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>user<|end_header_id|>  What is the role of model averaging in\n",
            "overcoming model uncertainty in equivalence tests, as discussed in recent arXiv\n",
            "publications?<|eot_id|><|start_header_id|>assistant<|end_header_id|> Model averaging is a technique\n",
            "used to address model uncertainty in equivalence testing by combining the results from multiple\n",
            "models or specifications. In recent arXiv publications, model averaging has been proposed as a way\n",
            "to overcome model uncertainty in equivalence tests.  In traditional equivalence testing, a single\n",
            "model is specified and tested for equality between two groups or treatments. However, this approach\n",
            "assumes that the true underlying relationship between the variables is accurately captured by the\n",
            "chosen model. In reality, there may be multiple plausible models that can explain the data equally\n",
            "well, leading to model uncertainty.  Model averaging addresses this issue by combining the results\n",
            "from multiple models or specifications. The idea is to average the estimates and standard errors\n",
            "across all models, rather than relying on a single model. This approach can help to:  1. **Reduce\n",
            "overfitting**: By combining multiple models, model averaging can reduce the risk of overfitting,\n",
            "which occurs when a model is too complex and fits the noise in the data. 2. **Improve robustness**:\n",
            "Model averaging can provide more robust estimates by averaging out the effects of individual model\n",
            "misspecifications. 3. **Account for model uncertainty**: By incorporating multiple models, model\n",
            "averaging acknowledges the uncertainty associated with model specification and provides a more\n",
            "comprehensive picture of the relationships between variables.  Recent arXiv publications have\n",
            "applied model averaging to equivalence testing in various contexts, including:  * **Non-parametric\n",
            "equivalence testing**: Model averaging has been used to combine non-parametric tests (e.g.,\n",
            "bootstrap-based tests) to improve the accuracy of equivalence testing. * **Bayesian equivalence\n",
            "testing**: Bayesian model averaging has been employed to combine posterior distributions from\n",
            "multiple models, allowing for the incorporation of prior knowledge and uncertainty quantification. *\n",
            "**Machine learning-based equivalence testing**: Model averaging has been applied to machine learning\n",
            "algorithms, such as neural networks, to improve the robustness of equivalence testing in high-\n",
            "dimensional settings.  By using model averaging in equivalence testing, researchers can gain\n",
            "insights into the robustness of their findings and better account for model uncertainty. This\n",
            "approach can lead to more reliable and generalizable conclusions about the absence or presence of\n",
            "differences between groups or treatments.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test with second prompt\n",
        "result = llm(prompt.format(text=prompt2))\n",
        "print(fill(result.strip(), width=100))"
      ],
      "metadata": {
        "id": "CIAyYjIEZSAa",
        "outputId": "5cd01994-94e4-4f73-a218-67e3a86952ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>user<|end_header_id|>  How do the proposed non-parametric\n",
            "spatial disease transmission models improve upon traditional parametric forms in estimating\n",
            "infection risk?<|eot_id|><|start_header_id|>assistant<|end_header_id|> Non-parametric spatial\n",
            "disease transmission models have several advantages over traditional parametric forms when it comes\n",
            "to estimating infection risk. Here are some ways they improve:  1. **Flexibility**: Non-parametric\n",
            "models don't rely on specific assumptions about the underlying distribution of the data, such as\n",
            "normality or Poisson distributions. This flexibility allows them to capture complex patterns and\n",
            "relationships that may not be captured by traditional parametric models. 2. **Robustness to\n",
            "outliers**: Parametric models can be sensitive to outliers, which can lead to biased estimates of\n",
            "infection risk. Non-parametric models are more robust to outliers, as they don't assume a specific\n",
            "distribution for the data. 3. **Ability to handle irregularly shaped boundaries**: Traditional\n",
            "parametric models often require regular boundaries (e.g., rectangular or circular) to define the\n",
            "study area. Non-parametric models can accommodate irregularly shaped boundaries, making them\n",
            "suitable for real-world applications where boundaries are often complex. 4. **Improved estimation of\n",
            "local risk**: Non-parametric models can provide more accurate estimates of local infection risk, as\n",
            "they account for spatial autocorrelation and heterogeneity in the data. This is particularly\n",
            "important in epidemiology, where understanding local risk is crucial for targeted interventions. 5.\n",
            "**Handling of missing data**: Non-parametric models can handle missing data more effectively than\n",
            "parametric models, which often require complete data sets. This is especially useful in situations\n",
            "where data is incomplete or sparse. 6. **Accounting for multiple factors**: Non-parametric models\n",
            "can incorporate multiple covariates and interactions between them, allowing for a more comprehensive\n",
            "understanding of the factors influencing infection risk. 7. **No need for prior knowledge of the\n",
            "distribution**: Unlike parametric models, non-parametric models don't require prior knowledge of the\n",
            "underlying distribution of the data. This makes them more appealing when working with limited or\n",
            "uncertain data. 8. **Computational efficiency**: Many non-parametric methods, such as kernel density\n",
            "estimation and k-nearest neighbors, are computationally efficient and can be implemented using\n",
            "standard algorithms.  Some examples of non-parametric spatial disease transmission models include:\n",
            "1. Spatial scan statistics: These methods use a scanning window approach to identify clusters of\n",
            "high-risk areas without assuming a specific distribution. 2. Kernel density estimation: This method\n",
            "uses a weighted average of nearby observations to estimate the probability density function of the\n",
            "data, allowing for flexible modeling of spatial patterns. 3. K-nearest neighbors: This method uses\n",
            "the distances between cases to estimate the risk of infection at a given location, accounting for\n",
            "spatial autocorrelation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test with third prompt\n",
        "result = llm(prompt.format(text=prompt3))\n",
        "print(fill(result.strip(), width=100))"
      ],
      "metadata": {
        "id": "1EKN7UTGZZ9h",
        "outputId": "20c3f9b8-164c-4dc5-b819-e09730e341a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>user<|end_header_id|>  What new procedures are proposed in\n",
            "quickest change detection to differentiate between 'bad' and 'confusing' changes, and what\n",
            "guarantees do these procedures offer?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "Quickest Change Detection (QCD) is a statistical method used to detect changes in data streams. To\n",
            "differentiate between \"bad\" and \"confusing\" changes, several new procedures have been proposed:  1.\n",
            "**Change Point Detection with Confidence Intervals**: This approach uses confidence intervals to\n",
            "determine the significance of detected changes. It provides a guarantee that the probability of\n",
            "false positives is bounded by the chosen significance level. 2. **Online Change Detection with\n",
            "Adaptive Windowing**: This procedure adapts the window size based on the data distribution, allowing\n",
            "it to better handle confusing changes. It offers a guarantee that the detection delay is minimized\n",
            "while maintaining a low false positive rate. 3. **Robust Change Detection using M-estimators**: This\n",
            "method uses robust statistics, such as M-estimators, to detect changes in the presence of outliers\n",
            "or heavy-tailed distributions. It provides a guarantee that the detection algorithm is resistant to\n",
            "contamination by atypical data points. 4. **Change Detection with Hierarchical Modeling**: This\n",
            "approach models the data using hierarchical structures, which allows for more accurate detection of\n",
            "changes. It offers a guarantee that the model can adapt to complex patterns in the data. 5.\n",
            "**Ensemble-based Change Detection**: This method combines multiple detectors to improve the accuracy\n",
            "and robustness of change detection. It provides a guarantee that the ensemble detector outperforms\n",
            "individual detectors in terms of detection accuracy and robustness.  These procedures offer various\n",
            "guarantees, including:  * **False Positive Rate (FPR)**: The probability of incorrectly detecting a\n",
            "change when no change has occurred. A lower FPR ensures that the detection algorithm is reliable and\n",
            "minimizes unnecessary alerts. * **Detection Delay**: The time elapsed between the occurrence of a\n",
            "true change and its detection. A shorter detection delay ensures that the system responds quickly to\n",
            "actual changes. * **Detection Accuracy**: The proportion of correctly detected changes. A high\n",
            "detection accuracy ensures that the system accurately identifies significant changes. *\n",
            "**Robustness**: The ability of the detection algorithm to perform well under varying conditions,\n",
            "such as changing data distributions or noisy data. Robust algorithms provide a guarantee that they\n",
            "will continue to function effectively even in challenging scenarios.  By incorporating these\n",
            "guarantees, Quickest Change Detection methods can be designed to effectively distinguish between\n",
            "\"bad\" and \"confusing\" changes, enabling more accurate and timely decision-making in applications\n",
            "such as quality control, finance, healthcare, and cybersecurity.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Create a LangChain-based RAG system by setting up a vector database from the documents. (20 points)"
      ],
      "metadata": {
        "id": "_7pv43WhZosp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the content from the web\n",
        "web_loader = UnstructuredURLLoader(\n",
        "    urls=urls, mode=\"elements\", strategy=\"fast\",\n",
        "    )\n",
        "web_doc = web_loader.load()\n",
        "updated_web_doc = filter_complex_metadata(web_doc)"
      ],
      "metadata": {
        "id": "Hvo1QPCvZqS8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into smaller chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2048, chunk_overlap=512)\n",
        "chunked_web_doc = text_splitter.split_documents(updated_web_doc)\n",
        "len(chunked_web_doc)"
      ],
      "metadata": {
        "id": "HoLoR_VIZ1bm",
        "outputId": "3572e8ae-e1b3-4d7e-daae-17fc403e9a2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3531"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a vector database\n",
        "embeddings = HuggingFaceEmbeddings()"
      ],
      "metadata": {
        "id": "SvX06APdaFMD",
        "outputId": "cc8ba54e-5b50-492e-ce49-dcc6dba53dc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use FAISS object to store the vector of objects\n",
        "%%time\n",
        "\n",
        "# Create the vectorized db with FAISS\n",
        "\n",
        "db_web = FAISS.from_documents(chunked_web_doc, embeddings)\n",
        "\n",
        "# Create the vectorized db with Chroma\n",
        "# from langchain.vectorstores import Chroma\n",
        "# db_web = Chroma.from_documents(chunked_web_doc, embeddings)"
      ],
      "metadata": {
        "id": "ciSMzVDiaO8s",
        "outputId": "a173ea95-1874-4920-d97a-a022e75d2caf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 7.95 s, sys: 89.5 ms, total: 8.04 s\n",
            "Wall time: 8.38 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate prompt template\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "\n",
        "Use the following context to answer the question at the end. Do not use any other information. If you can't find the relevant information in the context, just return an empty answer. Don't try to make up an answer.\n",
        "\n",
        "{context}<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ro1WXTUqagkr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up retrievalQA\n",
        "prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
        "Chain_web = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=db_web.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={'k': 10, 'score_threshold': 0.1}),\n",
        "    chain_type_kwargs={\"prompt\": prompt},\n",
        ")\n"
      ],
      "metadata": {
        "id": "V3pc5sdBa0_F"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Provide your three relevant and one irrelevant prompts to your RAG system. For the relevant prompts, your RAG system should return relevant answers, and for the irrelevant prompt, an empty answer. (20 points)"
      ],
      "metadata": {
        "id": "7mwzyt0xbZQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for hullucinations\n",
        "%%time\n",
        "result = Chain_web.invoke(prompt1)\n",
        "print(fill(result['result'].strip(), width=100))"
      ],
      "metadata": {
        "id": "YzuYS0xRa-9j",
        "outputId": "7701550f-a725-4bf9-917e-b5a758bbb5de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>  Use the following context to answer the\n",
            "question at the end. Do not use any other information. If you can't find the relevant information in\n",
            "the context, just return an empty answer. Don't try to make up an answer.  3.2 Model-based\n",
            "equivalence tests incorporating model averaging  Overcoming model uncertainty – how equivalence\n",
            "tests can benefit  3 Model-based equivalence tests under model uncertainty  In this paper, we\n",
            "introduced a new approach for model-based equivalence testing which can also be applied in the\n",
            "presence of model uncertainty – a problem which is usually faced in practical applications. Our\n",
            "approach is based on a flexible model averaging method which relies on information criteria and a\n",
            "testing procedure which makes use of the duality of tests and confidence intervals rather than\n",
            "simulating the distribution under the null hypothesis, providing a numerically stable procedure.\n",
            "Moreover, our approach leads to additional interpretability due to the provided confidence intervals\n",
            "while retaining the asymptotic validity and a similar performance in finite samples as the bootstrap\n",
            "based test proposed by Dette et al. (2018). Precisely, we investigated the finite sample properties\n",
            "of the proposed method by reanalysing the simulation study of Dette et al. (2018) and observed\n",
            "similar results for the CI-based test compared to their test. In the presence of model uncertainty,\n",
            "model misspecification frequently led to either type I error inflation or a lack of power, both\n",
            "often of substantial extend. In contrast, our approach considerably reduced these problems and in\n",
            "many cases even achieved similar results as knowing and using the true underlying model. The\n",
            "presented case study outlines the practical usefulness of the proposed method based on a large data\n",
            "application where choosing the models manually would be time-consuming and could easily lead to many\n",
            "model misspecifications. Hence, introducing model  Software in the form of R code available at\n",
            "https://github.com/Niklas191/equivalence_tests_ with_model_averaging.git. The case study data set is\n",
            "publicly available at the SRA database with reference number PRJNA953810.  Model-based equivalence\n",
            "tests have been introduced in terms of the L2-distance, the L1-distance or the maximal absolute\n",
            "deviation (also called L∞-distance) of the model curves (Dette et al., 2018; Bastian et al., 2024).\n",
            "Although all of these approaches have their specific advantages and disadvantages as well as\n",
            "specific applications, subsequent research (see, e.g., M¨ollenhoff et al., 2018, 2020, 2021;\n",
            "Hagemann et al., 2024) is predominately based on the maximal absolute deviation due to its easy\n",
            "interpretability. Accordingly, we state the hypotheses  increasing model complexity, this becomes\n",
            "numerically challenging. In the context of model averaging, these numerical issues are particularly\n",
            "relevant since all models would need to be estimated jointly as they need to jointly fulfil the\n",
            "constraint. This leads to a potentially high dimensional optimisation problem with a large number of\n",
            "parameters. In addition, for model averaging the side constraint has a highly complex structure\n",
            "because with every parameter update not only the model curves change but also the model weights do.\n",
            "As an alternative to approximating the distribution under the null hypothesis, we propose to test\n",
            "hypotheses (11) based on the well-known duality between confidence intervals and hypothesis testing\n",
            "(Aitchison, 1964). This testing approach is similar to what Bastian et al. (2024, Algorithm 1)\n",
            "intro- duced for the L1 distance of regression models. Therefore, let (−∞, u] be a one-sided lower\n",
            "(1 − α)-CI for d which we can rewrite as [0, u] due to the non-negativity of d, i.e.  Schorning, K.,\n",
            "Bornkamp, B., Bretz, F., and Dette, H. (2016). Model selection versus model averaging  We now\n",
            "investigate the finite sample properties under model uncertainty. Due to the clear superiority of\n",
            "the hybrid approach observed in Section 4.1, only the hybrid test is used for this analysis. We\n",
            "compare the performance of the test using model averaging to the one based on the correct\n",
            "specification of the models as well as under model misspecification. We use frequentist model\n",
            "averaging with AIC- based weights as the inference is frequentist as well. The corresponding\n",
            "equivalence tests are conducted using Algorithm 1b.  Fletcher, D. (2018). Model Averaging. Springer\n",
            "Briefs in Statistics. Springer.<|eot_id|><|start_header_id|>user<|end_header_id|>  What is the role\n",
            "of model averaging in overcoming model uncertainty in equivalence tests, as discussed in recent\n",
            "arXiv publications?<|eot_id|><|start_header_id|>assistant<|end_header_id|> According to the given\n",
            "text, model averaging plays a crucial role in overcoming model uncertainty in equivalence tests by\n",
            "providing a flexible approach that can handle multiple models simultaneously. It allows for the\n",
            "estimation of model weights based on information criteria such as AIC, which enables the\n",
            "incorporation of multiple models into a single test statistic. This approach reduces the impact of\n",
            "model misspecification, leading to improved performance in terms of type I error control and power,\n",
            "especially when compared to traditional methods that rely on a single model. Additionally, the use\n",
            "of model averaging provides additional interpretability through the provision of confidence\n",
            "intervals.\n",
            "CPU times: user 28.3 s, sys: 83.6 ms, total: 28.4 s\n",
            "Wall time: 28.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for hullucinations\n",
        "%%time\n",
        "\n",
        "result = Chain_web.invoke(prompt2)\n",
        "print(fill(result['result'].strip(), width=100))"
      ],
      "metadata": {
        "id": "bLmwcCqMbe8t",
        "outputId": "8ce0b7f7-c9bb-4d0f-b6f4-b77472bafa58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>  Use the following context to answer the\n",
            "question at the end. Do not use any other information. If you can't find the relevant information in\n",
            "the context, just return an empty answer. Don't try to make up an answer.  Parametric forms for\n",
            "spatial risk functions, or kernels, are often used, but rely on strong assumptions about underlying\n",
            "transmission mechanisms. Here, we propose a class of non- parametric spatial disease transmission\n",
            "model, fitted within a Bayesian Markov chain Monte Carlo (MCMC) framework, allowing for more\n",
            "flexible assumptions when estimating the effect on spatial distance and infection risk.  In real\n",
            "life, the individual or group-level factors likely have an impact on infection transmission or\n",
            "susceptibility. We could extend our model by incorporating covariates to consider more complex\n",
            "dynamics. For example, in our foot-and-mouth disease models we ignored the number of cattle and\n",
            "sheep on the farm, since we want to focus on the spatial aspect of disease spread. However, these\n",
            "are often used as covariates in such models (Deardon et al. [2010], Ward et al. [2023a]). It would\n",
            "also be of interest to develop semi-parametric forms of other epidemic models. For example, we could\n",
            "also consider including a so-called alarm function in our model to allow for the effect of disease\n",
            "prevalence-related behavioural change in the population over time (Ward et al. [2023a,b]) .\n",
            "Alternatively, the so-called geographically-dependent ILMs of Mahsin et al. [2022], which allow for\n",
            "both an individual and regional level spatial structure in the model, could be extended to allow for\n",
            "our piecewise spatial kernels.  For modeling infectious disease spread, parametric models have\n",
            "typically been used. This generally involves some strong underlying assumptions about the mechanisms\n",
            "of disease spread in the population. However, it is often difficult to determine appropriate\n",
            "parametric assumptions. In addition, in the context of epidemic models, often it is not clear how\n",
            "best to assess the goodness of fit of parametric models, and hence difficult to measure the extent\n",
            "to which the assumed underlying model assumptions are in line with observed data (Gardner et al.\n",
            "[2011], Xu et al. [2016], Kypraios and O’Neill [2018]). This may lead us to consider using a non-\n",
            "parametric approach which does not assume a simple, restrictive functional form and, hence, gives us\n",
            "greater flexibility.  Modelling epidemics is crucial for understanding the emergence, transmission,\n",
            "impact and control of diseases. Spatial individual-level models (ILMs) that account for population\n",
            "het- erogeneity are a useful tool, accounting for factors such as location, vaccination status and\n",
            "genetic information.  Mathematical modeling of infectious disease provides a tool to understand the\n",
            "emergence of a new disease, to predict its causes, characteristics, transmission, health impact, and\n",
            "to project the impact of control measures (Anonychuk and Krahn [2011], Basu and An- drews [2013],\n",
            "Keeling and Rohani [2011]). Over recent years, there has been a noticeable increase in research\n",
            "activity on spatio-temporal models to describe infectious disease dy- namics (Rotejanaprasert et al.\n",
            "[2019], O’Neill [2010], Deardon et al. [2010], Riley [2007]). Deardon et al. [2010] proposed a\n",
            "framework of discrete-time individual-level models (ILMs) which are highly intuitive and flexible,\n",
            "allowing the probability of a susceptible individual being infected depending on covariates\n",
            "associated with both the susceptible, and surround- ing infectious individuals. Note, the\n",
            "“individuals” in question may be individual people, plants or animals. However, we can also model at\n",
            "the level of aggregated units. The term “individual-level” is used since heterogeneities at whatever\n",
            "level we model at (for example, human, school, ranch, district, and so forth), are being accounted\n",
            "for. For example, geo- graphic location, vaccination status, or genetic information of the\n",
            "individual units can be accounted for.  In this paper, we develop a framework for simple piecewise\n",
            "spatial infectious disease transmission models in a Bayesian MCMC framework. This approach will help\n",
            "us to estimate the effect of spatial separation between individuals and the risk of infection with\n",
            "much more robust functional assumptions.  We focus upon two specific forms of non-parametric spatial\n",
            "infection kernel: piecewise constant and piecewise linear. Although these are relatively simple\n",
            "forms, we find them effective. The performance of these models is examined using simulated data,\n",
            "including under circumstances of model misspecification, and then applied to data from the UK 2001\n",
            "foot-and-mouth disease.  Gyanendra Pokharel and Rob Deardon. Emulation-based inference for spatial\n",
            "infectious disease transmission models incorporating event time uncertainty. Scandinavian Journal of\n",
            "Statistics, 49(1):455–479, 2022.  The layout of the rest of the paper is as follows. In Section 2,\n",
            "we introduce our proposed In Section 3, We demonstrate the semi-parametric spatial model and\n",
            "inference method. simulation process and the findings in detail. In Section 4, we apply our model to\n",
            "2001 UK foot-and-mouth disease (FMD) data and exhibit the outcome. Lastly, in Section 5, we offer\n",
            "plans for further research after summing up the study.  Abbie Gardner, Rob Deardon, and Gerarda A\n",
            "Darlington. Goodness-of-fit measures for individual-level models of infectious disease in a bayesian\n",
            "framework. Spatial and Spatio- temporal Epidemiology, 2(4):273–281,\n",
            "2011.<|eot_id|><|start_header_id|>user<|end_header_id|>  How do the proposed non-parametric spatial\n",
            "disease transmission models improve upon traditional parametric forms in estimating infection\n",
            "risk?<|eot_id|><|start_header_id|>assistant<|end_header_id|> According to the text, the proposed\n",
            "non-parametric spatial disease transmission models improve upon traditional parametric forms in\n",
            "estimating infection risk because they:  * Allow for more flexible assumptions about the underlying\n",
            "transmission mechanisms * Do not assume a simple, restrictive functional form, giving greater\n",
            "flexibility * Can accommodate complex dynamics and individual/group-level factors that affect\n",
            "infection transmission or susceptibility * Provide a more robust estimation of the effect of spatial\n",
            "separation between individuals and the risk of infection.\n",
            "CPU times: user 25.5 s, sys: 81.8 ms, total: 25.6 s\n",
            "Wall time: 29.7 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for hullucinations\n",
        "%%time\n",
        "\n",
        "result = Chain_web.invoke(prompt3)\n",
        "print(fill(result['result'].strip(), width=100))"
      ],
      "metadata": {
        "id": "7jv58Q8tbguD",
        "outputId": "93b996ef-5a04-40cf-e0ff-a95d3f33aa56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>  Use the following context to answer the\n",
            "question at the end. Do not use any other information. If you can't find the relevant information in\n",
            "the context, just return an empty answer. Don't try to make up an answer.  Quickest Change Detection\n",
            "with Confusing Change Y.-Z. Janice Chen∗, Jinhang Zuo∗, Venugopal V. Veeravalli‡, Don Towsley∗  [2]\n",
            "V. V. Veeravalli and T. Banerjee, “Quickest change detection,” in Elsevier, 2014, vol. 3,  While\n",
            "S-CuSum effectively detects the bad change and ig- nores the confusing change, its detection delay\n",
            "leaves room for improvement. Toward this, we propose Joint CuSum (J-CuSum), which incorporates two\n",
            "tests w.r.t. W [t] and Λ[t] respectively in a more involved way. Specifically, J-CuSum utilizes\n",
            "CuSumW (as defined in (17)) and let  Our contributions are as follows: In Section II, we formulate a\n",
            "novel quickest change detection problem where the change can be either a bad change or a confusing\n",
            "change, and takes not only the we propose a false alarm metric that run length to false alarm for\n",
            "pre-change but also the run  Scenarios 1 and 2 are trivial since simply applying a standard CuSum\n",
            "procedure suffices to quickly detect a bad change while avoiding raising a false alarm for a\n",
            "confusing change. In Figure 1, we illustrate the behavior of CuSumfB ,f0 in Scenario 1. As\n",
            "illustrated in Figure 1a, since in Scenario 1, CuSumfB ,f0 has a non-positive drift under confusing\n",
            "change fC (as under pre-change f0), CuSumfB ,f0 generally remains small after a confusing change\n",
            "occurs and will rarely trigger a false alarm. Figure 1b illustrates that CuSumfB ,f0 generally\n",
            "increases after a bad change occurs as it has a positive drift and quickly passes the alarm\n",
            "threshold. In Figure 2, we find that in Scenario 2 CuSumfB ,f0 fails to distinguish a bad change\n",
            "from confusing change because it has a positive drift under confusing change fC (as under bad change\n",
            "fB). Fortunately, applying a standard CuSumfB ,fC procedure suffices for our goal as it has non-\n",
            "positive drifts under both the pre-change and confusing change distributions and only has positive\n",
            "drift under the bad change distribution.  [21] T. S. Lau and W. P. Tay, “Quickest change detection\n",
            "in the presence of a nuisance change,” IEEE Transactions on Signal Processing, vol. 67, no. 20, pp.\n",
            "5281–5296, 2019.  Abstract—In the problem of quickest change detection (QCD), a change occurs at\n",
            "some unknown time in the distribution of a sequence of independent observations. This work studies a\n",
            "QCD problem where the change is either a bad change, which we aim to detect, or a confusing change,\n",
            "which is not of our interest. Our objective is to detect a bad change as quickly as possible while\n",
            "avoiding raising a false alarm for pre-change or a confusing change. We identify a specific set of\n",
            "pre-change, bad change, and confusing change distributions that pose challenges beyond the\n",
            "capabilities of standard Cumulative Sum (CuSum) procedures. Proposing novel CuSum-based detection\n",
            "procedures, S-CuSum and J-CuSum, leveraging two CuSum statistics, we offer solutions applicable\n",
            "across all kinds of pre-change, bad change, and confusing change distributions. For both S-CuSum and\n",
            "J-CuSum, we provide analytical performance guarantees and validate them by numerical results.\n",
            "Furthermore, both procedures are computationally efficient as they only require simple recursive\n",
            "updates.  [16] ——, “Sequential change-point detection when unknown parameters are  In Figure 6, we\n",
            "plot the average detection delays of the procedures against their average run lengths to false alarm\n",
            "for pre-change or for confusing change, whichever is smaller.This is because our false alarm\n",
            "requirement, Eq. (1), asks for both the run lengths to false alarm for pre-change and confusing\n",
            "change to be no smaller than the same threshold; hence, we plot against whichever is smaller to make\n",
            "sure that the requirement is fulfilled. Moreover, We plot run lengths to false alarm on a\n",
            "logarithmic scale while plotting detection delay on a linear scale. Hence, straight lines on the\n",
            "figures indicate that detection delays grow logarithmically with regard to run lengths to false\n",
            "alarm; whereas the steeply rising lines on the figures indicate that detection delays grow super-\n",
            "logarithmically with regard to run lengths to false alarm.  [4] L. Xie, S. Zou, Y. Xie, and V. V.\n",
            "Veeravalli, “Sequential (quickest) change detection: Classical results and new directions,” IEEE\n",
            "Journal on Selected Areas in Information Theory, vol. 2, no. 2, pp. 494–514,\n",
            "2021.<|eot_id|><|start_header_id|>user<|end_header_id|>  What new procedures are proposed in\n",
            "quickest change detection to differentiate between 'bad' and 'confusing' changes, and what\n",
            "guarantees do these procedures offer?<|eot_id|><|start_header_id|>assistant<|end_header_id|> The\n",
            "paper proposes two new procedures, S-CuSum and J-CuSum, to differentiate between \"bad\" and\n",
            "\"confusing\" changes. These procedures leverage two CuSum statistics, CuSumW and CuSumΛ,\n",
            "respectively.  S-CuSum and J-CuSum offer analytical performance guarantees, including:  * Detection\n",
            "delay guarantees: The procedures guarantee quick detection of bad changes while avoiding raising\n",
            "false alarms for pre-change or confusing changes. * Run length guarantees: The procedures ensure\n",
            "that the run length to false alarm for pre-change or confusing change is no smaller than a specified\n",
            "threshold.  These guarantees are validated through numerical results provided in the paper.\n",
            "CPU times: user 31.4 s, sys: 81.2 ms, total: 31.5 s\n",
            "Wall time: 31.6 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for hullucinations\n",
        "%%time\n",
        "\n",
        "result = Chain_web.invoke(i_prompt)\n",
        "print(fill(result['result'].strip(), width=100))"
      ],
      "metadata": {
        "id": "YANxKNSBbiAz",
        "outputId": "51a5ead5-ff1f-4bcb-db05-0ab811ad3006",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/vectorstores.py:330: UserWarning: Relevance scores must be between 0 and 1, got [(Document(page_content='nl 2', metadata={'page_number': 4, 'filetype': 'application/pdf', 'url': 'https://arxiv.org/pdf/2405.00827', 'category': 'Title'}), 0.2558730286617267), (Document(page_content='1 nl', metadata={'page_number': 5, 'filetype': 'application/pdf', 'url': 'https://arxiv.org/pdf/2405.00827', 'category': 'Title'}), 0.1501939364118139), (Document(page_content='max l,i', metadata={'page_number': 14, 'filetype': 'application/pdf', 'url': 'https://arxiv.org/pdf/2405.00827', 'category': 'Title'}), 0.05408285312345029), (Document(page_content='W L', metadata={'page_number': 3, 'filetype': 'application/pdf', 'url': 'https://arxiv.org/pdf/2405.00884', 'category': 'Title'}), 0.02134638436067471), (Document(page_content='W L', metadata={'page_number': 8, 'filetype': 'application/pdf', 'url': 'https://arxiv.org/pdf/2405.00884', 'category': 'Title'}), 0.02134638436067471), (Document(page_content='W W L', metadata={'page_number': 2, 'filetype': 'application/pdf', 'url': 'https://arxiv.org/pdf/2405.00884', 'category': 'Title'}), -0.00017404937007881038), (Document(page_content='l = 1, 2,', metadata={'page_number': 7, 'parent_id': '41f45c5b6fa881f570fd2e35a8b55a5d', 'filetype': 'application/pdf', 'url': 'https://arxiv.org/pdf/2405.00827', 'category': 'UncategorizedText'}), -0.0002999841534294667), (Document(page_content='l = 1, 2,', metadata={'page_number': 4, 'parent_id': '21e3c2efdafa8529d8cdc2b7cbb08b9c', 'filetype': 'application/pdf', 'url': 'https://arxiv.org/pdf/2405.00827', 'category': 'UncategorizedText'}), -0.0002999841534294667), (Document(page_content='l = 1, 2,', metadata={'page_number': 3, 'parent_id': '1ae69198a8f5f020e6c0b3f7fa28356e', 'filetype': 'application/pdf', 'url': 'https://arxiv.org/pdf/2405.00827', 'category': 'UncategorizedText'}), -0.00030023703452042305), (Document(page_content='1 1 0', metadata={'page_number': 7, 'parent_id': 'f80455cbc53e7801dd1f5ed2594a8c83', 'filetype': 'application/pdf', 'url': 'https://arxiv.org/pdf/2405.00884', 'category': 'UncategorizedText'}), -0.000614736818108863)]\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>  Use the following context to answer the\n",
            "question at the end. Do not use any other information. If you can't find the relevant information in\n",
            "the context, just return an empty answer. Don't try to make up an answer.  nl 2  1\n",
            "nl<|eot_id|><|start_header_id|>user<|end_header_id|>  Which team won Laliga this\n",
            "season?<|eot_id|><|start_header_id|>assistant<|end_header_id|> I'm sorry, but I couldn't find that\n",
            "information in the given context. The provided text does not mention La Liga or its winner for a\n",
            "specific season.\n",
            "CPU times: user 8.96 s, sys: 32.7 ms, total: 8.99 s\n",
            "Wall time: 9.38 s\n"
          ]
        }
      ]
    }
  ]
}